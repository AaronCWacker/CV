# NVidia
Advanced certifications or publications in AI, virtualization, cloud services, or related fields
Experience leading high-impact projects or initiatives in innovative tech domains
Proactive contributions to open-source projects or active involvement in tech communities
12+ years working as a Systems Architect, DevOps Engineer, Platform Engineer, or similarly technical IT systems architectural experience
Proven expertise in systems and networking architecture
Strong problem-solving skills with the ability to craft innovative solutions
Effective communication abilities and adept at translating sophisticated technical details to diverse audiences
A passion for staying updated with the latest technological advancements in AI and related fields

Architect, implement, and operate highly available messaging solutions using Microsoft Exchange (on-premises/hybrid/Exchange Online), Azure services, SMTP relays, and IMAP; establish and enforce architecture standards and best practices across regions/environments.
Plan and execute server upgrades and monthly patching; ensure configurations and changes meet compliance and audit requirements.
Monitor health, performance, and capacity; analyze logs/traces and protocol flows to prevent incidents, minimize downtime, and optimize throughput and user experience.
Provide expert-level diagnosis and resolution for complex mail flow issues; deep knowledge of SMTP/IMAP, connectors, transport rules, and messaging architecture.
Implement encryption, email authentication (SPF/DKIM/DMARC), and anti-virus/anti-spam protections (e.g., Microsoft Defender); maintain secure configurations and hardening baselines.
Lead/assist initiatives such as migrations, tenant consolidations, and M&A; define requirements and integration points with enterprise messaging and exchange apps and services.
Handle day-to-day operations and escalations; mentor engineers/architects and foster a culture of learning, documentation, SOPs, run-books, and enabling support team.
Build strategy to keep enhancing the messaging ecosystems with evolving technologies.

# Xai
The omni team at xAI creates magical AI experiences beyond text, enabling understanding and generation of content across various modalities, including image, video, and audio.
As a multimodal engineer, you will drive the development of real-time video and multimodal world models through various aspects such as data, modeling, training, serving, and product. You will work on both pretraining and posttraining and collaborate with product teams to push the frontiers of model capability as well as the end-to-end user experience.
Focus
Creating and driving agendas to advance real-time world simulation capabilities.
Improving data quality, developing data filtering/generation techniques, and performing data study.
Creating evaluation frameworks and internal benchmarks.
Designing and implementing effective and efficient algorithms for achieving state-of-the-art model performance.
Ideal Experiences
Track record in leading studies that significantly improves the capability and performance of neural networks, whether better data or better modeling.
Experience in data-driven experiment designs and systematic analysis for iterative model debugging.
Experience in developing or working with large-scale distributed machine learning systems.
Experience in graphics engines and rendering techniques is considered an advantage.
Ability to do whatever is necessary to deliver the best end-to-end user experience.
Location
The role is based in the Bay Area [San Francisco and Palo Alto] and Seattle, WA. Candidates are expected to be located near the Bay Area or Seattle or open to relocation.
Tech Stack
Python
Jax
Rust

Focus
Creating and driving engineering agenda to toward superhuman multimodal capabilities, which include both multimodal understanding and multimodal generation, across different modalities including image, video and audio.
Improving data quality, developing data filtering/generation techniques, and performing data study, on pretraining scale.
Creating evaluation frameworks and internal benchmarks.
Designing and implementing effective and efficient algorithms for achieving state-of-the-art model performance.
Ideal Experience
Hands-on experience on visual, audio or multimodal pretraining.
Track record in leading engineering that significantly improves the capability and performance of neural networks, whether better data or better modeling.
Experience in data-driven experiment designs and systematic analysis for iterative model debugging.
Experience in developing or working with large-scale distributed machine learning systems.
Ability to do whatever is necessary to deliver the best end-to-end user experience.
Tech Stack
Python
Jax
Rust

Tech Stack
Python / Rust / C++
Linux and POSIX
JAX and XLA
ibverbs, NVLink (NCCL)
CUDA (C++ and Triton)
Location
The role is based in Palo Alto, CA. Candidates are expected to be located near the Bay Area or open to relocation.

Focus
Design, build, and implement large-scale distributed training systems.
Profiling, debugging, and optimizing multi-host GPU utilization.
Hardware / Software / Algorithm co-design.
Maintain and innovate on the codebase.
Build tools to boost the productivity of the team.
Ideal Experiences
Experience in configuring and troubleshooting operating systems for maximum performance. 
Built scalable training framework for AI models in HPC clusters, including but not limited to
Scalable orchestration framework and tools
Machine learning compilers and runtime such as XLA, MLIR, and Triton
Distributed training strategies such as FSDP, Megatron, and pipeline parallelism
NCCL or custom communication libraries for performant communication collectives

About the Team

The AI Expert team strives to build AI Scientists, Engineers, and Professionals. We train Grok to solve the most challenging agentic tasks in the real world, which require long-horizon reasoning, planning, and decision making. We have started in some high-impact domains—including math, chemistry, biology, material science, and finance—and will expand to more. Our daily work includes model evaluation, data curation, and training recipe development. We also work closely with xAI enterprise and product teams to create and improve our products and services.

About the Role

In this role you might:

Innovate next-generation RL algorithms to unleash AI abilities in open-ended science developments and real-world professional work.
Build evaluation for AI models in various applied domains.
Build RL data infrastructure and generate training data.
Exceptional candidates may have:

Strong engineering abilities.
Experience with data collection and data generation for LLMs.
Optional: Research and professional experiences in non-CS domains, such as math, physics, and finance.
Location

We hire engineers in Palo Alto. Our team usually works from the office 5 days a week but allow work-from-home days when required. Candidates are expected to be located near Palo Alto or open to relocation.


The Grok Code Team at xAI focuses on pushing the boundaries of Software Engineering where AI is in the front and centre of the full developer loop.

About the Role

In this role you will:

You will build the best in class Coding Agents focussing on building the best in class Software Engineering stack which is AI first and AI native.
Work across the LLM stack (reasoning RL, product building, dataset generation, evals) to deliver the best product experience for users.
Work closely with the research team and help drive model development and feedback loops to optimise both the model behavior and user experience and satisfaction
Exceptional candidates may have:

Experience in developer tooling with AI first mindset for the changing world.
Exceptional engineering skills to iterate quickly on the data processing and product features
Strong understanding of large language model and how to best leverage them for AI assisted software development
Deep knowledge and “taste” in software developer tooling
Location

We hire engineers in Palo Alto. Our team usually works from the office 5 days a week but allow work-from-home days when required. Candidates are expected to be located near Palo Alto or open to relocation.
Interview Process

After submitting your application, the team reviews your CV and statement of exceptional work. If your application passes this stage, you will be invited to a 15-minute interview (“phone interview”) during which a member of our team will ask some basic questions. If you clear the initial phone interview, you will enter the main process, which consists of four technical interviews:

Coding assessment in a language of your choice.
2x post-training technical sessions: These sessions will be testing your ability to formulate, design and solve concrete problems in training data for post-training.
Meet the Team: Present your past exceptional work and your vision with xAI to a small audience.
Our goal is to finish the main process within one week. All interviews will be conducted via Google Meet.


About the Team

The Grok Code Team at xAI focuses on pushing the boundaries of Software Engineering where AI is in the front and centre of the full developer loop.

About the Role

In this role you will:

Develop cutting-edge coding products, such as command-line interfaces (CLIs) and remote agents, to deliver an exceptional user experience aligned with our vision of advancing AI-driven software engineering.
Collaborate closely with both individual and enterprise users to gather feedback, iteratively improve, and rapidly ship high-quality products.
Contribute to the model development loop by providing feedback, setting up evaluations, collecting data, and assisting in training AI models to enhance performance and user satisfaction.
Exceptional candidates may have:

Regular experience using coding agents in their daily workflows.
A proven track record of building useful and delightful products, with examples shared in their applications.
Experience developing products or tools on top of existing coding agents to enhance workflows or leverage advanced, lesser-known capabilities of these agents.
Deep knowledge and a refined sense of "taste" in software developer tooling.
Location

We hire engineers in Palo Alto. Our team usually works from the office 5 days a week but allow work-from-home days when required. Candidates are expected to be located near Palo Alto or open to relocation.


The Reasoning Efficiency team at xAI focuses on pushing the boundaries of cost-efficient intelligence.

About the Role

In this role you will:

Build the next generation of Multimodal Grok that excels at reasoning, tool usage to solve challenging problems
Work across the LLM stack (pre-training, SFT, RL) to deliver the strongest model for end users. Some projects will involve real-time video understanding, including data curation, pipelines, and evaluation for video-based multimodal capabilities
Exceptional candidates may have:

Experience or publications in (multimodal) large language models (data / training algorithm / architecture)
Exceptional engineering skills to iterate quickly on the data processing and training pipelines
Strong understanding of large language model and data
Deep knowledge of reinforcement learning techniques
Deep knowledge of reinforcement learning techniques - Experience in real-world computer vision, video processing, or multimodal datasets (e.g., real-time video understanding, noisy visual data handling, or scalable video pipelines)


The Reasoning Efficiency team at xAI focuses on pushing the boundaries of cost-efficient intelligence.

About the Role

In this role you will:

Build the next generation of Grok Mini - highly efficient reasoning models with frontier-level performance 
Innovate scalable techniques to maximize intelligence per dollar
Work across the LLM stack (reasoning RL, pretraining, serving) to deliver the strongest model for end users
Exceptional candidates may have:

Experience or publications in efficient algorithms for large language models (data / training algorithm / architecture)
Exceptional engineering skills to iterate quickly on the data processing and training pipelines
Strong understanding of large language model scaling laws 
Deep knowledge of reinforcement learning techniques


As a Member of Technical Staff - Reasoning Post-training at xAI, you will drive the evolution of our AI models' reasoning capabilities through inventive post-training approaches, embracing a broad scope that spans from conceptual exploration to practical implementation. This role demands a blend of technical depth and boundless creativity, where you'll refine pre-trained models to excel in logical inference, multi-step problem-solving, and adaptive thinking—without delving into initial training phases. By devising unconventional techniques and fostering creative breakthroughs, you'll help our AI systems tackle complex, real-world challenges with unprecedented intelligence and reliability, collaborating across teams to turn bold ideas into transformative enhancements.

Focus

Post-Training Optimization: Apply and innovate on post-training methods like fine-tuning, reinforcement learning variants, or data augmentation to sharpen reasoning skills, ensuring models deliver more accurate, coherent, and insightful outputs.
Creative Methodology Design: Invent novel strategies for enhancing reasoning, such as custom prompting frameworks, synthetic reasoning datasets, or hybrid techniques that push the limits of model cognition through out-of-the-box thinking.
Problem-Solving Exploration: Tackle broad reasoning challenges creatively, from debugging logical inconsistencies to engineering solutions for edge-case scenarios, using iterative experimentation to uncover hidden potential in models.
Evaluation and Iteration: Develop creative benchmarks and metrics to assess post-training impacts on reasoning, enabling rapid cycles of refinement that align with evolving user needs and technological frontiers.
Collaborative Innovation: Partner with diverse teams to integrate post-training advancements into our AI ecosystem, leveraging your creativity to inspire cross-pollination of ideas and accelerate overall model intelligence.
Ideal Experience

Post-Training Specialization: Extensive hands-on experience with post-training techniques (e.g., RLHF, DPO, or alignment methods) focused on reasoning improvements, with a portfolio of successful model enhancements.
Creative Problem-Solving Prowess: Demonstrated ingenuity in solving ambiguous AI challenges, evidenced by innovative projects, contributions, or unconventional approaches that yielded breakthroughs.
Broad Technical Foundation: Proficiency in engineering tools (e.g., Python, PyTorch) and a solid grasp of model architectures, enabling you to navigate wide-ranging tasks from ideation to deployment.
Analytical Versatility: Background in AI development with emphasis on reasoning, logic, or cognitive science, including publications or experiments that highlight creative applications in post-training contexts.
Adaptable Expertise: 3+ years in multifaceted AI roles at cutting-edge organizations, where you've thrived in broad scopes by balancing creativity with rigorous execution to deliver high-impact results.


Pretrain team at xAI aims to answer the question: How to scale up intelligence by scaling up compute effectively? 

This question can be further broken down into two sub-questions:

What to scale up
How to scale up
What to scale up:

Next-token prediction is a meaningful target for the time where online data is large enough, but model size can not grow as much. As we enter the new phase, model size is growing faster than data, therefore we need a new scaling paradigm.
At xAI, our compute grows much faster than other companies. We believe scaling up effective compute / useful data is the best path to achieve next-level intelligence.
What is  “effective compute” or “useful data”? This is the first question this role is expected to explore and answer. It could be solid data cleaning and scaling, could be discovering new knowledge via self-improvement, could be a new learning paradigm like continual learning, could be unified models of text / code / images / videos understanding and generation, could be new model architectures / attention / non-autoregressive models... Anything that has the potential to be the next scaling paradigm is open to exploration.
How to scale up:

Remember we are aiming at several hundreds of millions GPU hours of training, any tiny training stability issue will ruin the big run.
So this role also needs to explore how to do large-scale and long-time training. For example, most reasoning and postraining phases <1k steps, think about scaling to 10k to 100k steps of training and the model still stably improves like a typical successful pretraining run. This is the goal we also want to achieve.


The omni team at xAI creates magical AI experiences beyond text, enabling understanding and generation of content across various modalities, including image, video, and audio.

As a multimodal engineer focused on Video Generation - Agent, RL, you will pioneer AI agents that perceive, reason about, and generate video content. You will advance both video understanding (e.g., temporal reasoning, action recognition, long-horizon prediction) and video generation (e.g., controllable generation, long-video planning/generation) within agentic systems.

Tech Stack
Python
JAX
SGLang
Spark
Ray

The omni team at xAI creates magical AI experiences beyond text, enabling understanding and generation of content across various modalities, including image, video, and audio.

You will craft the ultimate multimodal data recipe for training an omni-model that unlocks the universe's secrets through image, audio and video. To achieve this vision, we're seeking visionary engineers with deep expertise in video data.

Focus
Discover and source video datasets with crawling team.
Building scalable infrastructure for video data curation and management.
Craft insightful experiments to assess video dataset performance.
Innovate the recipe for scaling video pre-training data..
Ideal Experiences
Keeping up with state-of-the-art techniques for preparing multimodal training data.
Strong ability to design ML experiments.
Familiarity with state-of-the-art techniques for curating AI training data for image, audio and video modalities.
Strong engineering abilities in Spark, Ray, and other frameworks for large-scale data processing..


Tech Stack
Python
JAX and XLA
Rust / C++
Spark / Ray
Focus
Training trillion parameter multimodal models at the web scale, as well as a variety of smaller specialized models.
Pushing boundaries in spatial-temporal compression, world modeling, multimodal reasoning, cross-modal alignment, and emergent capabilities.
Rapidly implementing the latest state-of-the-art methods from the deep learning literature.
Innovating new ideas for pretraining and new scaling paradigm.
Ideal Experience
Strong engineering skills with passion on model-hardware co-design.
Expert in ML and large model scaling, familiar with all kinds of scaling laws.
Familiar with distributed training, multi-GPU neural network training and experience on optimizing ML training efficiency.
Familiar with state-of-the-art techniques for multimodal language models, especially for image/video understanding.


As a Member of Technical Staff, you will build frameworks to improve the reasoning capability, build distributed reinforcement learning systems, techniques for inference time compute (e.g. tree search and planning), and develop environments for agents.

You will get exposure and will be expected to solve and take ownership of components across the entire stack.

Tech Stack
Python
JAX
Rust
Location
The role is based in the Bay Area [San Francisco and Palo Alto]. Candidates are expected to be located in the Bay Area or open to relocation.

Focus
Build robust and scalable distributed RL systems.
Optimize frameworks to enable complex inference-time reasoning.
Develop environments and harnesses for agents.
Ideal Experiences
Experienced with large-scale reinforcement learning systems.
Designing and implementing distributed systems.
Keeping up with state-of-the-art RL and inference time compute algorithms.

About the Role
The omni team at xAI creates magical AI experiences beyond text, enabling understanding and generation of content across various modalities, including image, video, and audio.

As a software infrastructure engineer on multimodal, you will develop and optimize scalable frameworks and software for large-scale machine-learning tasks, including model training, inference, and large-scale data processing. You will work together with other members in the omni team and the product team to push the frontiers of model capability as well as the end-to-end user experience.

Focus
Design, build, and implement large-scale distributed training systems.
Profiling, debugging, and optimizing GPU utilization for multimodal model training and inference.
Building scalable infrastructure for multimodal data management and crawling.
Hardware / Software / Algorithm co-design.
Ideal Experiences
Strong engineering skills with passion to improve different aspects of data and model.
Has worked on one or more modalities other than text for model training/serving optimization.
Keeping up with state-of-the-art techniques for preparing multimodal training data.

Tech Stack
Kubernetes
Buildkite / ArgoCD
Prometheus  / Grafana /  PagerDuty
Pulumi / Terraform
SGLang: This team is actively working on one of the most popular open-source inference engines, SGLang. You have the opportunity to work on open-source projects. 
Custom debugging and tracing tools
Focus
Architect and implement scalable distributed infrastructure for model serving, such as load balancing, auto scaling, batch scheduling, and global KVcache systems.
Ensure the reliability of inference services, targeting 100% uptime, a 0% error rate, and good tail performance, through proactive monitoring, fault-tolerant designs, and rigorous testing.
Create custom tools to trace, replay, and fix issues or crashes across the entire stack, from cluster orchestration to GPU kernels.
Benchmark and fine-tune inference engines to deliver optimal performance under diverse, production workloads.
Develop robust CI/CD infrastructure to enable seamless endpoint deployment, image publishing, feature rollouts, and inference engine updates.
Ideal Experiences
Worked on large-scale, high-concurrent production serving.
Worked on GPU inference engines.
Worked on testing, benchmarking, and the reliability of inference services.
Worked on designing and implementing CI/CD infrastructure.
Location

Focus
Creating and driving engineering agenda to toward superhuman multimodal capabilities, which include both multimodal understanding and multimodal generation, across different modalities including image, video and audio.
Improving data quality, developing data filtering/generation techniques, and performing data study, on pretraining scale.
Creating evaluation frameworks and internal benchmarks.
Designing and implementing effective and efficient algorithms for achieving state-of-the-art model performance.
Ideal Experience
Hands-on experience on visual, audio or multimodal pretraining.
Track record in leading engineering that significantly improves the capability and performance of neural networks, whether better data or better modeling.
Experience in data-driven experiment designs and systematic analysis for iterative model debugging.
Experience in developing or working with large-scale distributed machine learning systems.
Ability to do whatever is necessary to deliver the best end-to-end user experience.
Tech Stack
Python
Jax
Rust

Focus
Creating and driving engineering agenda to toward superhuman multimodal capabilities, which include both multimodal understanding and multimodal generation, across different modalities including image, video and audio.
Improving data quality, developing data filtering/generation techniques, and performing data study, on pretraining scale.
Creating evaluation frameworks and internal benchmarks.
Designing and implementing effective and efficient algorithms for achieving state-of-the-art model performance.
Ideal Experience
Hands-on experience on visual, audio or multimodal pretraining.
Track record in leading engineering that significantly improves the capability and performance of neural networks, whether better data or better modeling.
Experience in data-driven experiment designs and systematic analysis for iterative model debugging.
Experience in developing or working with large-scale distributed machine learning systems.
Ability to do whatever is necessary to deliver the best end-to-end user experience.
Tech Stack
Python
Jax
Rust

Focus
Creating and driving research agenda to advance image and video generation and editing capabilities.
Improving data quality, developing data filtering/generation techniques, and performing data study.
Creating evaluation frameworks and internal benchmarks.
Designing and implementing effective and efficient algorithms for achieving state-of-the-art model performance.
Ideal Experiences
Track record in leading research that significantly improves the capability and performance of neural networks, whether better data or better modeling.
Experience in data-driven experiment designs and systematic analysis for iterative model debugging.
Experience in developing or working with large-scale distributed machine learning systems.
Experience in graphics engines and rendering techniques is considered an advantage.
Ability to do whatever is necessary to deliver the best end-to-end user experience.

Focus

Developing agentic planners for image generation. 
Designing and collecting human/synthetic data; developing data generation techniques, e.g., captioning.
Building evals and reward models for image generation.
Studying training recipes for advancing image / multi-image understanding/generation and agent training.
Ideal Experience

Track record in leading studies that significantly improve the capability and performance of neural networks, whether through better data or better modeling.
Experience in data-driven experiment designs and systematic analysis for iterative model debugging.
Experience in SFT, RL, evals, and human/synthetic data.
Experience in agentic RL training models is considered an advantage.
Interview Process
After submitting your application, the team reviews your CV and statement of exceptional work. If your application passes this stage, you will be invited to a 15 minute interview (“phone interview”) during which a member of our team will ask some basic questions. If you clear the initial phone interview, you will enter the main process, which consists of four technical interviews:

One-on-one discussion & coding interviews (three meetings total)
Project deep-dive: Present your past exceptional work and your vision with xAI to a small audience.

# MS

Starting January 26, 2026, MAI employees are expected to work from a designated Microsoft office at least four days a week if they live within 50 miles (U.S.) or 25 miles (non-U.S., country-specific) of that location. This expectation is subject to local law and may vary by jurisdiction.

Microsoft Superintelligence Team
Microsoft Superintelligence team’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

This role is part of Microsoft AI’s Superintelligence Team. The MAIST is a startup-like team inside Microsoft AI, created to push the boundaries of AI toward Humanist Superintelligence—ultra-capable systems that remain controllable, safety-aligned, and anchored to human values. Our mission is to create AI that amplifies human potential while ensuring humanity remains firmly in control. We aim to deliver breakthroughs that benefit society—advancing science, education, and global well-being.

We’re also fortunate to partner with incredible product teams giving our models the chance to reach billions of users and create immense positive impact. If you’re a brilliant, highly-ambitious and low ego individual, you’ll fit right in—come and join us as we work on our next generation of models! 



Responsibilities
Design and develop data pipelines that ingest enormous amounts of multi-modal training data (text, audio, images, video).

Own and maintain critical data infrastructures, including spark, ray, vector databases, and others.

Build and maintain cutting-edge infrastructure that can store and process the petabytes of data needed to power models.

Partner with the pretraining and post-training teams to improve our data recipe by rigorous and careful experimentation.

Microsoft Superintelligence Team
Microsoft Superintelligence team’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

This role is part of Microsoft AI’s Superintelligence Team. The MAIST is a startup-like team inside Microsoft AI, created to push the boundaries of AI toward Humanist Superintelligence—ultra-capable systems that remain controllable, safety-aligned, and anchored to human values. Our mission is to create AI that amplifies human potential while ensuring humanity remains firmly in control. We aim to deliver breakthroughs that benefit society—advancing science, education, and global well-being.

We’re also fortunate to partner with incredible product teams giving our models the chance to reach billions of users and create immense positive impact. If you’re a brilliant, highly-ambitious and low ego individual, you’ll fit right in—come and join us as we work on our next generation of models! 



Responsibilities
Design and develop data pipelines that ingest enormous amounts of multi-modal training data (text, audio, images, video).

Own and maintain critical data infrastructures, including spark, ray, vector databases, and others.

Build and maintain cutting-edge infrastructure that can store and process the petabytes of data needed to power models.

Partner with the pretraining and post-training teams to improve our data recipe by rigorous and careful experimentation.

Embody our culture and values.




Microsoft Superintelligence Team
Microsoft Superintelligence team’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

This role is part of Microsoft AI’s Superintelligence Team. The MAIST is a startup-like team inside Microsoft AI, created to push the boundaries of AI towardHumanist Superintelligence—ultra-capable systems that remain controllable, safety-aligned, and anchored to human values. Our mission is to create AI that amplifies human potential while ensuring humanity remains firmly in control. We aim to deliver breakthroughs that benefit society—advancing science, education, and global well-being.

We’re also fortunate to partner with incredible product teams giving our models the chance to reach billions of users and create immense positive impact. If you’re a brilliant, highly-ambitious and low ego individual, you’ll fit right in—come and join us as we work on our next generation of models!



Responsibilities
Leverage subject matter expertise to improve model quality for interactive and agentive experiences.
Oversee data acquisition or generation efforts, ensuring that the data meets the model needs.
Generalize machine learning (ML) solutions into repeatable frameworks.
Lead evaluation efforts of models, including those deployed within Microsoft products and the Cloud API.
Track advances in industry and academia, identifies relevant state-of-the-art research, and adapts algorithms and/or techniques to drive innovation and develop new solutions.
Independently write efficient, readable, extensible code and model pipelines.
Commit to a customer-oriented focus by acknowledging customer needs and perspectives and building AI products that delight customers.



